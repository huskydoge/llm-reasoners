{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T15:23:26.493869Z",
     "start_time": "2023-07-22T15:23:26.490035Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/adithya/anaconda3/envs/reasoners/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import modules\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.append('..') \n",
    "# the data structure for blocksworld is defined in the parent directory\n",
    "from reasoners.visualization import visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T15:11:44.345695Z",
     "start_time": "2023-07-22T15:11:41.138585Z"
    }
   },
   "outputs": [],
   "source": [
    "from tot_inference import ProntoQAState\n",
    "# load the log\n",
    "with open(\"../../logs/prontoqa_DFS/12182023-002452/algo_output/27.pkl\", 'rb') as f:\n",
    "    dfs_result = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Polly is a cat.',\n",
       " 'Cats are felines.',\n",
       " 'So Polly is a feline.',\n",
       " 'Felines are carnivores.',\n",
       " 'So Polly is a carnivore.',\n",
       " 'Every carnivore is a mammal.',\n",
       " 'So Polly is a mammal.',\n",
       " 'Mammals are warm-blooded.',\n",
       " 'So Polly is warm-blooded.',\n",
       " 'The answer is true.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_result.terminal_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customize the information to show (optional)\n",
    "from reasoners.visualization.tree_snapshot import NodeData, EdgeData\n",
    "# from reasoners.algorithm.mcts import MCTSNode\n",
    "\n",
    "def blocksworld_node_data_factory(n) -> NodeData:\n",
    "    return NodeData({\"state\": \"\\n\".join(n.state) if n.state else \"Not expanded\"})\n",
    "def blocksworld_edge_data_factory(n) -> EdgeData:\n",
    "    # print(f'self eval: { n.reward_details[\"self_eval\"]}')\n",
    "    return EdgeData({\"intuition\": n.reward_details[\"intuition\"], \"action\": n.action, \"self_eval\": n.reward_details[\"self_eval\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualizer URL: https://www.llm-reasoners.net/visualizer/822941f4-1304-40ec-8d6e-62e2bd928ded?accessKey=e86a2faf\n"
     ]
    }
   ],
   "source": [
    "# let's go!\n",
    "visualize(bfs_result, node_data_factory=blocksworld_node_data_factory, edge_data_factory=blocksworld_edge_data_factory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize for multiple MCTS Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Visualizer URL: https://www.llm-reasoners.net/visualizer/e9240249-7c22-48de-983e-78490eda95e5?accessKey=8cf78454\n",
      "9\n",
      "Visualizer URL: https://www.llm-reasoners.net/visualizer/54fd353c-76e4-498e-8dd0-1fa03b8d0644?accessKey=5dd944bd\n",
      "10\n",
      "Visualizer URL: https://www.llm-reasoners.net/visualizer/0206b98e-98d9-4311-b7e5-cd2d6c69691b?accessKey=4a9a18c2\n",
      "11\n",
      "Visualizer URL: https://www.llm-reasoners.net/visualizer/f0ba684a-e357-442f-8e9e-d2dc9a7bd006?accessKey=bdef0f9f\n",
      "13\n",
      "Visualizer URL: https://www.llm-reasoners.net/visualizer/020c78b7-94d5-45a3-a189-27358af470f6?accessKey=17264082\n",
      "14\n",
      "Visualizer URL: https://www.llm-reasoners.net/visualizer/71b96f18-fbec-473c-8338-b7f2e28a092e?accessKey=86895753\n",
      "15\n",
      "Visualizer URL: https://www.llm-reasoners.net/visualizer/6fd2b04d-4558-4478-a4e6-3b1138bab3b0?accessKey=bd44fcea\n",
      "16\n",
      "Visualizer URL: https://www.llm-reasoners.net/visualizer/7a17db6d-aa0e-409d-9e56-45766efd7c84?accessKey=d9828c0c\n",
      "17\n",
      "Visualizer URL: https://www.llm-reasoners.net/visualizer/d180907e-ac0d-49fd-8751-c58a87ede627?accessKey=c5e42ba6\n"
     ]
    }
   ],
   "source": [
    "from tot_inference import ProntoQAState\n",
    "# load the log\n",
    "for i in [6, 9, 10, 11, 13, 14, 15, 16, 17]:\n",
    "    with open(f\"../../logs/MCTS_{i}.pkl\", 'rb') as f:\n",
    "        dfs_result = pickle.load(f)\n",
    "    print(i)\n",
    "    visualize(dfs_result, node_data_factory=blocksworld_node_data_factory, edge_data_factory=blocksworld_edge_data_factory)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Visualizer URL: https://www.llm-reasoners.net/visualizer/fbd123e4-19ba-4494-9940-77ce92e35f0a?accessKey=41e7009b\n"
     ]
    }
   ],
   "source": [
    "from tot_inference import ProntoQAState\n",
    "# load the log\n",
    "for i in [1]:\n",
    "    with open(f\"../../logs/MCTS_{i}.pkl\", 'rb') as f:\n",
    "        dfs_result = pickle.load(f)\n",
    "    print(i)\n",
    "    visualize(dfs_result, node_data_factory=blocksworld_node_data_factory, edge_data_factory=blocksworld_edge_data_factory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output extractor: Alex is a lepidopteran.\n",
      "Alex is an insect.\n",
      "Alex is an arthropod.\n",
      "Alex is not bony.\n",
      "Alex is six-legged.\n"
     ]
    }
   ],
   "source": [
    "from tot_inference import ProntoQAState\n",
    "import torch\n",
    "\n",
    "\n",
    "def bfs_pronto_extractor(algo_output):\n",
    "        if torch.distributed.is_initialized():\n",
    "            torch.distributed.barrier()\n",
    "        # to make sure the plan is saved before evaluation in multi-process setting\n",
    "        try:\n",
    "            answer = \"\\n\".join(algo_output.terminal_node.state[2::2])\n",
    "            answer = answer.replace(\"So \", \"\")\n",
    "            return answer\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Error in output extraction,\", e)\n",
    "            return \"\"\n",
    "    \n",
    "def dfs_bw_extractor(algo_output):\n",
    "    if torch.distributed.is_initialized():\n",
    "        torch.distributed.barrier()\n",
    "    # to make sure the plan is saved before evaluation in multi-process setting\n",
    "    try:\n",
    "        answer = \"\\n\".join(algo_output.terminal_state[2::2])\n",
    "        answer = answer.replace(\"So \", \"\")\n",
    "        return answer\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error in output extraction,\", e)\n",
    "        return \"\"\n",
    "        \n",
    "\n",
    "# load the log\n",
    "for i in [1]:\n",
    "    with open(f\"../../logs/MCTS_{i}.pkl\", 'rb') as f:\n",
    "        dfs_result = pickle.load(f)\n",
    "        search_algo=\"beam\"\n",
    "        output_extractor = dfs_bw_extractor if search_algo == \"dfs\" else bfs_pronto_extractor\n",
    "        answer_extractor= lambda x: x.test_example.answer\n",
    "        output = output_extractor(dfs_result)\n",
    "        # answer = self.answer_extractor(example)\n",
    "\n",
    "        # print(f\"answer extractor: { answer}\")\n",
    "        print(f\"output extractor: {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 5, 7, 9]\n"
     ]
    }
   ],
   "source": [
    "list_ex= [1,2,3,4,5,6,7,8,9]\n",
    "print(list_ex[2::2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alex is a lepidopteran.\n",
      "Alex is an insect.\n",
      "Alex is six-legged.\n"
     ]
    }
   ],
   "source": [
    "chain_of_thought=['Alex is a butterfly.', 'Each butterfly is a lepidopteran.', 'Alex is a lepidopteran.', 'Lepidopterans are insects.', 'Alex is an insect.', 'Every insect is six-legged.', 'Alex is six-legged.']\n",
    "answer_extractor=lambda x: \"\\n\".join(x[2::2])\n",
    "\n",
    "print(answer_extractor(chain_of_thought))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
